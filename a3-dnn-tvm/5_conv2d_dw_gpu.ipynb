{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-HW-SYS/a3-anya-23-ct/blob/main/5_conv2d_dw_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# Depthwise-seperable 2D Convolution on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD2GHA5WVSow"
      },
      "source": [
        "## 1. Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnmfRsiBVSow",
        "outputId": "31a1bdad-56bf-4ba7-fe58-d4fd9b6a022a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rR5CmYuCVSox"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username\n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZHBLuQfVSox",
        "outputId": "2ec82e7a-922e-46ca-f633-0a4d2d0895bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545\n",
            "/content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "M\t3-conv1d_fpga.ipynb\n",
            "M\t5_conv2d_dw_gpu.ipynb\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 378 bytes | 6.00 KiB/s, done.\n",
            "From https://github.com/ML-HW-SYS/a3-anya-23-ct\n",
            "   a4a1726..de49b70  main       -> origin/main\n",
            "Updating a4a1726..de49b70\n",
            "Fast-forward\n",
            " src/ops.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "# %mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "# !git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QfJNPVatVSox"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Bztq-VVSoy",
        "outputId": "a7991b13-8b15-48f5-e405-85e2c81476ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_conv1d_cpu.ipynb  3-conv1d_fpga.ipynb  5_conv2d_dw_gpu.ipynb\tREADME.md  tests\n",
            "2_conv1d_gpu.ipynb  4_gemm_gpu.ipynb\t leaderboard_id.txt\tsrc\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EghxXWHSVyZR"
      },
      "source": [
        "## 2 Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phf10Wb1VxoB",
        "outputId": "33920925-095d-4088-9c70-520956e98f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.12.dev/tlcpack_nightly_cu102-0.15.dev118%2Bg51bdaec6e-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.6/428.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (1.11.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (4.11.0)\n",
            "Installing collected packages: tlcpack-nightly-cu102\n",
            "Successfully installed tlcpack-nightly-cu102-0.15.dev118+g51bdaec6e\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1dTOTtqVSoy"
      },
      "source": [
        "## 3. Implement `make_dwsp_conv2d_gpu_scheduler` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 2D convolution and use TVM to optimize it.\n",
        "Please use zero padding and unit stride.\n",
        "You can assume kernel size to be an odd number.\n",
        "The padding will equals to kernel size minus ones.\n",
        "In this case, the output image will preserve the input image dimension.\n",
        "\n",
        "The `make_dwsp_conv2d_gpu_scheduler` takes following arguments:\n",
        "1. Batch size $B$;\n",
        "2. Input channel size $C$;\n",
        "3. Input image height $H$;\n",
        "4. Input image width $W$;\n",
        "5. Output number of channels $O$;\n",
        "6. Kernel size $K$\n",
        "\n",
        "You should return both the TVM scheduler and the TVM opterator for\n",
        "1. Input tensor $x$ with size (B, C, H, W)\n",
        "2. Input kernel weight $y$ with size (O, 1, K, K)\n",
        "3. Output $out$ with size (B, O, H, W)\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$.\n",
        "Please see the following cells the usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rbp2mmTVSoz",
        "outputId": "e1458d65-d018-4562-fc3c-9862cb3bb49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: [[[[ 3.3085604  5.4952455  5.7319655 ...  8.067335   6.448019\n",
            "     4.866012 ]\n",
            "   [ 4.912408   4.6070194  6.2031045 ...  7.691306   6.6890016\n",
            "     4.5963297]\n",
            "   [ 4.958172   6.4360023  7.180133  ... 10.454654   8.899951\n",
            "     6.2019672]\n",
            "   ...\n",
            "   [ 7.5075     7.329874   9.383095  ...  7.867528   6.5494347\n",
            "     3.9976702]\n",
            "   [ 5.5932813  6.060118   7.592796  ...  6.6397448  5.644244\n",
            "     3.233382 ]\n",
            "   [ 4.358755   5.2905345  5.8813543 ...  5.1563425  4.6399117\n",
            "     2.8146594]]\n",
            "\n",
            "  [[ 4.354756   5.401951   6.505598  ...  6.046861   4.039886\n",
            "     3.0361319]\n",
            "   [ 5.537532   6.2455845  8.215389  ...  6.83536    5.061315\n",
            "     3.6397796]\n",
            "   [ 7.345904   7.9559155  9.64554   ...  8.31967    6.487497\n",
            "     4.533555 ]\n",
            "   ...\n",
            "   [ 4.344213   6.1993246  9.180506  ...  7.1866517  6.3072047\n",
            "     5.4909673]\n",
            "   [ 4.1907954  5.566031   6.4878144 ...  6.630461   5.6072884\n",
            "     4.3224173]\n",
            "   [ 2.301276   4.364054   5.706177  ...  5.4244947  4.317024\n",
            "     3.717177 ]]\n",
            "\n",
            "  [[ 5.4084587  5.368762   5.6852484 ...  5.9201856  5.1259236\n",
            "     3.7467453]\n",
            "   [ 4.553035   6.0427637  8.040079  ...  7.9476314  6.5798\n",
            "     4.6090293]\n",
            "   [ 6.4042206  8.197668   8.563546  ...  9.181771   7.3704667\n",
            "     5.828226 ]\n",
            "   ...\n",
            "   [ 6.963281   8.1142     8.477607  ...  6.512227   5.3830214\n",
            "     4.674133 ]\n",
            "   [ 5.507528   6.1365085  6.404894  ...  6.269409   4.594306\n",
            "     4.315446 ]\n",
            "   [ 4.1159067  4.772527   4.9100018 ...  4.687177   4.167851\n",
            "     3.0804987]]\n",
            "\n",
            "  [[ 4.2483807  4.1416807  5.2150564 ...  6.375377   4.567925\n",
            "     3.4002416]\n",
            "   [ 4.564114   5.496284   6.4413204 ...  7.7371325  4.338699\n",
            "     4.2793207]\n",
            "   [ 5.456438   6.6496987  8.418659  ...  8.472967   6.4129915\n",
            "     4.284494 ]\n",
            "   ...\n",
            "   [ 5.5205674  6.6136703  8.024887  ...  8.529101   6.785543\n",
            "     5.472762 ]\n",
            "   [ 5.045735   5.69002    7.1888223 ...  7.245042   5.9310365\n",
            "     4.722398 ]\n",
            "   [ 4.1277223  5.055845   5.6971197 ...  5.7189465  4.392411\n",
            "     3.4187806]]]\n",
            "\n",
            "\n",
            " [[[ 4.145589   4.796372   4.5880523 ...  8.260414   5.164925\n",
            "     4.9669404]\n",
            "   [ 5.5230374  6.056669   6.7994246 ...  8.9400835  5.209459\n",
            "     4.075974 ]\n",
            "   [ 6.0346546  7.0567193  8.827874  ... 10.752776   6.875853\n",
            "     6.044604 ]\n",
            "   ...\n",
            "   [ 5.334007   6.644047   6.9279037 ...  8.312279   5.533766\n",
            "     3.1692135]\n",
            "   [ 5.8750567  5.7372174  6.033154  ...  6.124773   4.113344\n",
            "     2.8738108]\n",
            "   [ 4.04145    3.977977   5.3321786 ...  4.345081   3.2291389\n",
            "     2.3573098]]\n",
            "\n",
            "  [[ 4.816804   5.8617845  5.8937674 ...  5.8377166  4.03394\n",
            "     3.1864247]\n",
            "   [ 5.067164   6.690569   7.302286  ...  6.7289605  4.6567187\n",
            "     2.8325708]\n",
            "   [ 6.009542   6.555662   9.391058  ...  7.675504   6.006993\n",
            "     4.4107766]\n",
            "   ...\n",
            "   [ 6.155132   8.668194   8.894577  ...  7.250645   6.2893715\n",
            "     4.4920077]\n",
            "   [ 4.2904773  5.83933    7.7285104 ...  5.9578457  4.474329\n",
            "     3.9030523]\n",
            "   [ 3.5758867  4.441035   4.702433  ...  4.1193237  4.3173666\n",
            "     3.0148885]]\n",
            "\n",
            "  [[ 3.9140563  5.604195   7.0867143 ...  7.4119954  4.580873\n",
            "     4.5045624]\n",
            "   [ 4.738134   5.036173   7.1508193 ...  8.294057   5.020999\n",
            "     5.0760927]\n",
            "   [ 5.5326734  6.606406   8.598802  ...  9.148501   8.596647\n",
            "     6.593792 ]\n",
            "   ...\n",
            "   [ 6.426118   6.708499   9.241961  ... 10.668447   9.893448\n",
            "     6.9790897]\n",
            "   [ 5.8715353  7.0700574  8.1051855 ...  9.14246    8.046796\n",
            "     5.783038 ]\n",
            "   [ 4.9731593  5.817027   6.79311   ...  7.1992965  5.0239706\n",
            "     4.8533297]]\n",
            "\n",
            "  [[ 4.3352146  4.5061684  4.799591  ...  4.206879   3.8556392\n",
            "     2.677447 ]\n",
            "   [ 4.2701497  5.259303   6.1205125 ...  6.2903295  4.317327\n",
            "     3.2794   ]\n",
            "   [ 5.5683966  7.070786   7.3265767 ...  7.243283   5.446269\n",
            "     4.837228 ]\n",
            "   ...\n",
            "   [ 6.497376   8.537093   9.534114  ...  8.8469925  7.8975277\n",
            "     5.530766 ]\n",
            "   [ 5.6677375  6.8109784  8.514936  ...  8.513777   7.239188\n",
            "     6.127575 ]\n",
            "   [ 4.5757775  5.150879   6.0784645 ...  6.6002355  5.409889\n",
            "     3.6166716]]]\n",
            "\n",
            "\n",
            " [[[ 3.3201864  4.4258165  5.6126614 ...  6.179047   4.117235\n",
            "     2.9672132]\n",
            "   [ 4.770708   6.604847   6.9798827 ...  6.8141994  5.3549166\n",
            "     4.427383 ]\n",
            "   [ 6.0046945  7.02001    6.90384   ...  8.412881   7.124891\n",
            "     5.5638328]\n",
            "   ...\n",
            "   [ 4.3197184  6.2842236  8.18497   ...  7.8105683  7.7409453\n",
            "     4.9796524]\n",
            "   [ 4.188703   5.392879   5.0675035 ...  6.974261   5.598028\n",
            "     3.6100564]\n",
            "   [ 2.9615715  3.992884   4.9935417 ...  5.1510015  4.2944584\n",
            "     2.4665835]]\n",
            "\n",
            "  [[ 5.7412715  5.6386237  5.1208224 ...  5.678207   3.679198\n",
            "     2.6628087]\n",
            "   [ 6.1232443  7.107061   6.389602  ...  6.368319   5.0146537\n",
            "     2.9552615]\n",
            "   [ 7.3304167  7.4573927  7.633907  ...  7.8802223  5.702423\n",
            "     4.4171333]\n",
            "   ...\n",
            "   [ 6.7108874  8.087086   9.754536  ...  8.185327   6.8143177\n",
            "     4.651126 ]\n",
            "   [ 5.286827   6.8727665  8.741987  ...  6.0172787  3.9721975\n",
            "     3.6811254]\n",
            "   [ 4.8305383  5.5307183  6.550166  ...  4.129408   4.072862\n",
            "     2.814453 ]]\n",
            "\n",
            "  [[ 4.9322696  5.3537674  6.317073  ...  5.321319   3.3172424\n",
            "     2.7565129]\n",
            "   [ 4.370993   5.7943835  6.7841253 ...  5.7675     4.864899\n",
            "     3.9922726]\n",
            "   [ 5.3964024  6.80874    7.601455  ...  8.580753   6.138735\n",
            "     4.8079643]\n",
            "   ...\n",
            "   [ 5.915857   7.499246  10.142206  ...  8.506633   7.0906863\n",
            "     6.2450767]\n",
            "   [ 4.7459636  6.3634434  7.967508  ...  7.8003755  5.5272217\n",
            "     4.681192 ]\n",
            "   [ 3.8621812  5.8072376  6.017195  ...  6.0457573  3.934642\n",
            "     3.244262 ]]\n",
            "\n",
            "  [[ 3.8513694  5.9069986  6.0630608 ...  6.770325   5.222251\n",
            "     3.8512137]\n",
            "   [ 5.4533963  5.939188   7.9968987 ...  6.4802556  6.742187\n",
            "     3.6941915]\n",
            "   [ 6.5470114  7.3114653  7.9485784 ...  8.664049   6.977254\n",
            "     4.663999 ]\n",
            "   ...\n",
            "   [ 6.1560516  7.756414   8.136654  ...  8.456563   6.963683\n",
            "     4.574518 ]\n",
            "   [ 4.2608604  6.411021   7.2732186 ...  6.978529   6.172983\n",
            "     4.7002106]\n",
            "   [ 3.1470602  3.6969283  4.730769  ...  5.1289763  3.889033\n",
            "     3.2998693]]]]\n",
            "2DConv TVM: 0.122879 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_dwsp_conv2d_gpu_scheduler\n",
        "\n",
        "B = 3\n",
        "C = 4\n",
        "H = 16\n",
        "W = 32\n",
        "K = 7\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(B, C, H, W).astype(dtype)\n",
        "w_np = np.random.rand(C, 1, K, K).astype(dtype)\n",
        "\n",
        "s, inp, ker, out = make_dwsp_conv2d_gpu_scheduler(B, C, H, W, K)\n",
        "func = tvm.build(s, [inp, ker, out], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((B, C, H, W), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "print(\"Output:\", b)\n",
        "print(f\"2DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtM-xfNHVSoz",
        "outputId": "e1a7d541-f8f6-4869-f804-1902d78c7eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), out: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        pad_in = T.allocate([10032], \"float32\", \"global\")\n",
            "        pad_in_1 = T.Buffer((10032,), data=pad_in)\n",
            "        for i0, i1 in T.grid(3, 4):\n",
            "            blockIdx_z = T.launch_thread(\"blockIdx.z\", 11)\n",
            "            threadIdx_z = T.launch_thread(\"threadIdx.z\", 2)\n",
            "            blockIdx_y = T.launch_thread(\"blockIdx.y\", 19)\n",
            "            threadIdx_y = T.launch_thread(\"threadIdx.y\", 2)\n",
            "            A_1 = T.Buffer((6144,), data=A.data)\n",
            "            pad_in_1[i0 * 3344 + i1 * 836 + blockIdx_z * 76 + threadIdx_z * 38 + blockIdx_y * 2 + threadIdx_y] = T.if_then_else(blockIdx_z * 2 + threadIdx_z < 3 or 19 <= blockIdx_z * 2 + threadIdx_z or blockIdx_y * 2 + threadIdx_y < 3 or 35 <= blockIdx_y * 2 + threadIdx_y, T.float32(0), A_1[i0 * 2048 + i1 * 512 + blockIdx_z * 64 + threadIdx_z * 32 + blockIdx_y * 2 + threadIdx_y - 99])\n",
            "        for b, c in T.grid(3, 4):\n",
            "            blockIdx_x = T.launch_thread(\"blockIdx.x\", 8)\n",
            "            threadIdx_x = T.launch_thread(\"threadIdx.x\", 2)\n",
            "            blockIdx_y = T.launch_thread(\"blockIdx.y\", 16)\n",
            "            threadIdx_y = T.launch_thread(\"threadIdx.y\", 2)\n",
            "            out_1 = T.Buffer((6144,), data=out.data)\n",
            "            out_1[b * 2048 + c * 512 + blockIdx_x * 64 + threadIdx_x * 32 + blockIdx_y * 2 + threadIdx_y] = T.float32(0)\n",
            "            for ki, kj in T.grid(7, 7):\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                out_1[b * 2048 + c * 512 + blockIdx_x * 64 + threadIdx_x * 32 + blockIdx_y * 2 + threadIdx_y] = out_1[b * 2048 + c * 512 + blockIdx_x * 64 + threadIdx_x * 32 + blockIdx_y * 2 + threadIdx_y] + pad_in_1[b * 3344 + c * 836 + blockIdx_x * 76 + threadIdx_x * 38 + ki * 38 + blockIdx_y * 2 + threadIdx_y + kj] * W_1[c * 49 + ki * 7 + kj]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [inp, ker, out], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE2DD12GVSoz",
        "scrolled": false,
        "outputId": "25b405df-030e-4e77-c0bf-28d63d96f9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.4.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "plugins: anyio-3.7.1\n",
            "collected 1357 items                                                                               \u001b[0m\n",
            "\n",
            "tests/test_dwsp_2dconv_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [  4%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 11%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 18%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 24%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 31%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 38%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 45%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 52%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 58%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 65%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 72%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 79%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 85%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 92%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m [ 99%]\n",
            "\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                      [100%]\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[10] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 10\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 10x speed-up failed: TVM Time: 4.03999e-03s TorchTime: 3.26224e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0040399869999419025 * 10.0) <= 0.03262239600007888\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[20] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 20\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 20x speed-up failed: TVM Time: 2.93188e-03s TorchTime: 5.01888e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0029318830002011964 * 20.0) <= 0.05018882800004576\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[30] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 30\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 30x speed-up failed: TVM Time: 3.42558e-03s TorchTime: 6.27561e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0034255789996677777 * 30.0) <= 0.06275613500019972\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[40] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 40\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 40x speed-up failed: TVM Time: 3.30731e-03s TorchTime: 4.62864e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.003307309000319947 * 40.0) <= 0.046286407000025065\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[50] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 50\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 50x speed-up failed: TVM Time: 2.37538e-03s TorchTime: 4.86233e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002375379000113753 * 50.0) <= 0.0486233220003669\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[60] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 60\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 60x speed-up failed: TVM Time: 2.33131e-03s TorchTime: 3.64041e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002331306000087352 * 60.0) <= 0.03640410600019095\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[70] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 70\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 70x speed-up failed: TVM Time: 2.42806e-03s TorchTime: 3.37370e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0024280630000248493 * 70.0) <= 0.033737012000074174\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[80] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 80\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 80x speed-up failed: TVM Time: 2.38638e-03s TorchTime: 3.43288e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0023863770002208184 * 80.0) <= 0.03432879000001776\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[90] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 90\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 90x speed-up failed: TVM Time: 2.30184e-03s TorchTime: 3.50656e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0023018369997771515 * 90.0) <= 0.03506560400001035\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[100] ______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 100\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 100x speed-up failed: TVM Time: 2.28145e-03s TorchTime: 2.97262e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0022814549997747235 * 100.0) <= 0.02972621099979733\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[10]\u001b[0m - AssertionError: 10x speed-up failed: TVM Time: 4.03999e-03s TorchTime: 3.26224e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[20]\u001b[0m - AssertionError: 20x speed-up failed: TVM Time: 2.93188e-03s TorchTime: 5.01888e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[30]\u001b[0m - AssertionError: 30x speed-up failed: TVM Time: 3.42558e-03s TorchTime: 6.27561e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[40]\u001b[0m - AssertionError: 40x speed-up failed: TVM Time: 3.30731e-03s TorchTime: 4.62864e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[50]\u001b[0m - AssertionError: 50x speed-up failed: TVM Time: 2.37538e-03s TorchTime: 4.86233e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[60]\u001b[0m - AssertionError: 60x speed-up failed: TVM Time: 2.33131e-03s TorchTime: 3.64041e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[70]\u001b[0m - AssertionError: 70x speed-up failed: TVM Time: 2.42806e-03s TorchTime: 3.37370e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[80]\u001b[0m - AssertionError: 80x speed-up failed: TVM Time: 2.38638e-03s TorchTime: 3.43288e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[90]\u001b[0m - AssertionError: 90x speed-up failed: TVM Time: 2.30184e-03s TorchTime: 3.50656e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[100]\u001b[0m - AssertionError: 100x speed-up failed: TVM Time: 2.28145e-03s TorchTime: 2.97262e-02s\n",
            "\u001b[31m=========================== \u001b[31m\u001b[1m10 failed\u001b[0m, \u001b[32m1347 passed\u001b[0m\u001b[31m in 836.72s (0:13:56)\u001b[0m\u001b[31m ============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_dwsp_2dconv_gpu.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Optimisation"
      ],
      "metadata": {
        "id": "5gIfIHBdIWDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_dwsp_conv2d_gpu_scheduler\n",
        "\n",
        "B = 3\n",
        "C = 4\n",
        "H = 16\n",
        "W = 32\n",
        "K = 7\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(B, C, H, W).astype(dtype)\n",
        "w_np = np.random.rand(C, 1, K, K).astype(dtype)\n",
        "\n",
        "s, inp, ker, out = make_dwsp_conv2d_gpu_scheduler(B, C, H, W, K)\n",
        "func = tvm.build(s, [inp, ker, out], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((B, C, H, W), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "print(\"Output:\", b)\n",
        "print(f\"2DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_0EZFGEIXvP",
        "outputId": "078450ba-c65a-4370-ddf2-1baa374b6bd6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: [[[[ 5.1544003  5.8808637  8.224626  ...  6.2984886  5.96336\n",
            "     4.3654714]\n",
            "   [ 6.8383126  7.5007644  9.456376  ...  7.6629796  7.161763\n",
            "     4.9138427]\n",
            "   [ 8.108542   8.747515  11.457553  ... 10.224314   7.4862905\n",
            "     6.5296154]\n",
            "   ...\n",
            "   [ 6.9277368  8.752855  10.285544  ...  8.655933   7.1696286\n",
            "     5.183069 ]\n",
            "   [ 6.086805   7.5314403  8.239422  ...  7.282843   6.1466146\n",
            "     4.3259053]\n",
            "   [ 4.6753883  4.852292   6.5419607 ...  4.9141173  4.809478\n",
            "     3.4151871]]\n",
            "\n",
            "  [[ 4.268148   5.979646   6.6704874 ...  5.3198843  4.8047056\n",
            "     4.8257375]\n",
            "   [ 4.0216293  5.849429   7.2215014 ...  6.7832327  5.9706035\n",
            "     4.366134 ]\n",
            "   [ 5.9203835  7.623722   9.781009  ...  8.637326   7.7504587\n",
            "     6.1455   ]\n",
            "   ...\n",
            "   [ 5.3856606  6.642796   6.7991385 ...  9.147945   8.207213\n",
            "     6.609198 ]\n",
            "   [ 3.6262195  5.48802    5.6210656 ...  8.538963   6.840046\n",
            "     5.6348567]\n",
            "   [ 3.743722   3.6602774  5.03133   ...  5.743079   4.907499\n",
            "     4.5882735]]\n",
            "\n",
            "  [[ 5.233818   6.268291   6.6232486 ...  6.487425   5.1880894\n",
            "     4.029957 ]\n",
            "   [ 5.6648636  6.37876    7.093838  ...  7.0708146  6.591484\n",
            "     4.207617 ]\n",
            "   [ 6.4564137  7.1427665  7.44368   ...  8.168031   7.1568804\n",
            "     5.319089 ]\n",
            "   ...\n",
            "   [ 6.24298    7.475367   8.583428  ...  7.7135634  7.1253624\n",
            "     5.904043 ]\n",
            "   [ 5.3420897  5.400807   7.003079  ...  5.786601   6.2144833\n",
            "     4.631716 ]\n",
            "   [ 3.5444999  4.399335   5.1356153 ...  4.710629   4.4066515\n",
            "     3.4286437]]\n",
            "\n",
            "  [[ 3.7600958  4.258323   5.501906  ...  6.571917   4.9105625\n",
            "     4.662788 ]\n",
            "   [ 4.3891892  5.1000175  7.2124567 ...  9.122155   6.5154634\n",
            "     6.501376 ]\n",
            "   [ 5.0397067  6.0179763  7.8272243 ... 10.010499   8.111676\n",
            "     7.8505034]\n",
            "   ...\n",
            "   [ 6.623779   8.485743  11.1245985 ...  9.168003   7.1306586\n",
            "     7.059983 ]\n",
            "   [ 4.340753   6.474223   8.836826  ...  7.62732    6.619968\n",
            "     6.2543154]\n",
            "   [ 4.6696057  5.042211   7.2938547 ...  6.773912   5.424709\n",
            "     5.5621543]]]\n",
            "\n",
            "\n",
            " [[[ 4.087864   6.0898523  7.893615  ...  6.800148   5.6938667\n",
            "     5.7145553]\n",
            "   [ 4.822006   7.5816894  9.220397  ...  6.644647   5.4644604\n",
            "     4.672226 ]\n",
            "   [ 6.890137   7.5899434 10.248705  ...  9.918406   7.3802614\n",
            "     5.783319 ]\n",
            "   ...\n",
            "   [ 5.5943675  8.045123   7.9638247 ...  9.343227   7.8023057\n",
            "     6.3052297]\n",
            "   [ 5.7232685  5.785875   7.831043  ...  7.66914    7.1504025\n",
            "     6.441911 ]\n",
            "   [ 2.9481602  4.290825   3.8369882 ...  4.606215   4.380019\n",
            "     3.844958 ]]\n",
            "\n",
            "  [[ 3.5192652  4.259482   5.193421  ...  6.0223484  5.4469113\n",
            "     4.5374675]\n",
            "   [ 4.1670237  5.4289827  6.1498127 ...  7.339837   6.999268\n",
            "     6.343214 ]\n",
            "   [ 5.741732   8.038185   9.888917  ...  9.274565   8.209212\n",
            "     7.371459 ]\n",
            "   ...\n",
            "   [ 6.258729   7.3745527  8.879419  ...  8.876591   7.921563\n",
            "     6.2263846]\n",
            "   [ 5.4419785  6.286591   7.1099997 ...  7.717804   4.9949713\n",
            "     3.8639042]\n",
            "   [ 5.908801   6.0520844  6.352258  ...  6.0237527  4.8246417\n",
            "     3.6720643]]\n",
            "\n",
            "  [[ 3.530324   4.7088876  6.1849313 ...  6.873749   6.451278\n",
            "     5.1407003]\n",
            "   [ 3.4827607  5.914758   6.3607054 ...  7.825581   7.72523\n",
            "     6.2068806]\n",
            "   [ 4.677763   4.889779   7.645191  ...  9.803915   9.5121565\n",
            "     7.4247904]\n",
            "   ...\n",
            "   [ 6.0911355  6.850471   7.8874383 ...  8.829453   7.383915\n",
            "     6.1739173]\n",
            "   [ 5.1528573  5.9702244  6.5313945 ...  7.2598324  5.817191\n",
            "     5.130891 ]\n",
            "   [ 3.320681   4.8787174  4.9572053 ...  4.908564   4.1026587\n",
            "     3.564311 ]]\n",
            "\n",
            "  [[ 4.2222733  5.268152   6.97058   ...  5.8065705  5.065193\n",
            "     4.508052 ]\n",
            "   [ 5.2076683  6.659006   8.831444  ...  7.4110208  6.4078164\n",
            "     6.0294304]\n",
            "   [ 6.168211   8.353558  11.14984   ...  9.314587   7.639157\n",
            "     7.076945 ]\n",
            "   ...\n",
            "   [ 5.372727   6.837628   7.87963   ...  8.286715   7.1355963\n",
            "     5.784526 ]\n",
            "   [ 4.0031605  4.4726095  6.0109234 ...  7.3155613  5.6305466\n",
            "     4.7252064]\n",
            "   [ 3.2340407  3.5792835  4.506841  ...  6.9078836  5.7254972\n",
            "     4.066081 ]]]\n",
            "\n",
            "\n",
            " [[[ 4.9668317  6.343904   7.0635114 ...  7.038493   5.407089\n",
            "     4.329316 ]\n",
            "   [ 5.52256    7.2335877  8.206485  ...  8.208771   5.8708735\n",
            "     5.02995  ]\n",
            "   [ 6.5008693  8.303125   9.030389  ...  9.813838   7.820366\n",
            "     7.052584 ]\n",
            "   ...\n",
            "   [ 7.90336    8.428898   9.431638  ... 10.229726   8.859099\n",
            "     7.356433 ]\n",
            "   [ 6.0754523  6.986279   8.300468  ...  7.9462943  7.7103777\n",
            "     5.672725 ]\n",
            "   [ 4.5019007  5.7924466  5.000269  ...  5.9302764  5.3222075\n",
            "     5.134807 ]]\n",
            "\n",
            "  [[ 4.3162737  5.6996927  6.8643966 ...  6.639901   5.5582595\n",
            "     4.235519 ]\n",
            "   [ 5.244893   6.53735    6.9514546 ...  8.325044   5.8302226\n",
            "     6.0077167]\n",
            "   [ 6.4078026  7.123149   8.95687   ...  9.88383    7.53887\n",
            "     6.0644517]\n",
            "   ...\n",
            "   [ 6.3344364  6.3724284  8.889467  ...  9.433108   7.767821\n",
            "     6.203383 ]\n",
            "   [ 5.0133605  6.7551117  7.619373  ...  7.300044   5.8631463\n",
            "     5.026724 ]\n",
            "   [ 4.252832   4.6584888  5.6061654 ...  5.8632493  4.918526\n",
            "     4.2085185]]\n",
            "\n",
            "  [[ 2.819914   3.5131826  3.5834556 ...  6.5699964  5.610771\n",
            "     4.965474 ]\n",
            "   [ 3.3453152  4.113412   5.214285  ...  7.988011   7.0664315\n",
            "     6.1204596]\n",
            "   [ 3.7985444  5.525771   5.9110436 ...  9.815194   8.496242\n",
            "     7.31463  ]\n",
            "   ...\n",
            "   [ 6.2697625  7.955657   9.611702  ...  8.182435   7.088587\n",
            "     5.101621 ]\n",
            "   [ 4.0638885  6.509798   6.910252  ...  6.0797186  5.825493\n",
            "     3.4494364]\n",
            "   [ 3.924287   4.953446   5.6783004 ...  5.424056   3.781976\n",
            "     2.7137246]]\n",
            "\n",
            "  [[ 3.6849024  4.880203   6.816296  ...  7.664155   5.903857\n",
            "     5.180258 ]\n",
            "   [ 4.8007402  6.07082    7.901768  ...  9.250968   7.2043767\n",
            "     6.296735 ]\n",
            "   [ 6.539813   7.431334  10.086224  ...  9.444763   7.166041\n",
            "     7.0412593]\n",
            "   ...\n",
            "   [ 5.947322   7.787149  10.1069355 ... 10.486905   8.487736\n",
            "     7.0070033]\n",
            "   [ 4.593027   6.0582776  7.6132116 ...  9.064381   7.571763\n",
            "     6.614038 ]\n",
            "   [ 3.8755863  5.545685   6.7247663 ...  7.361725   6.488401\n",
            "     5.77453  ]]]]\n",
            "2DConv TVM: 0.116736 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [inp, ker, out], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pobcdmw7IX7X",
        "outputId": "2f41ec64-dff5-4272-8324-b15cbd66f40d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), out: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        pad_in = T.allocate([10032], \"float32\", \"global\")\n",
            "        pad_in_1 = T.Buffer((10032,), data=pad_in)\n",
            "        for i0, i1 in T.grid(3, 4):\n",
            "            blockIdx_z = T.launch_thread(\"blockIdx.z\", 6)\n",
            "            blockIdx_y = T.launch_thread(\"blockIdx.y\", 10)\n",
            "            threadIdx_z = T.launch_thread(\"threadIdx.z\", 4)\n",
            "            threadIdx_y = T.launch_thread(\"threadIdx.y\", 4)\n",
            "            if T.likely(blockIdx_z * 2 + threadIdx_z // 2 < 11):\n",
            "                if T.likely(blockIdx_y * 2 + threadIdx_y // 2 < 19):\n",
            "                    A_1 = T.Buffer((6144,), data=A.data)\n",
            "                    pad_in_1[i0 * 3344 + i1 * 836 + blockIdx_z * 152 + threadIdx_z * 38 + blockIdx_y * 4 + threadIdx_y] = T.if_then_else(blockIdx_z * 4 + threadIdx_z < 3 or 19 <= blockIdx_z * 4 + threadIdx_z or blockIdx_y * 4 + threadIdx_y < 3 or 35 <= blockIdx_y * 4 + threadIdx_y, T.float32(0), A_1[i0 * 2048 + i1 * 512 + blockIdx_z * 128 + threadIdx_z * 32 + blockIdx_y * 4 + threadIdx_y - 99])\n",
            "        for b, c in T.grid(3, 4):\n",
            "            blockIdx_x = T.launch_thread(\"blockIdx.x\", 4)\n",
            "            blockIdx_y = T.launch_thread(\"blockIdx.y\", 8)\n",
            "            threadIdx_x = T.launch_thread(\"threadIdx.x\", 4)\n",
            "            threadIdx_y = T.launch_thread(\"threadIdx.y\", 4)\n",
            "            out_1 = T.Buffer((6144,), data=out.data)\n",
            "            out_1[b * 2048 + c * 512 + blockIdx_x * 128 + threadIdx_x * 32 + blockIdx_y * 4 + threadIdx_y] = T.float32(0)\n",
            "            for ki, kj in T.grid(7, 7):\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                out_1[b * 2048 + c * 512 + blockIdx_x * 128 + threadIdx_x * 32 + blockIdx_y * 4 + threadIdx_y] = out_1[b * 2048 + c * 512 + blockIdx_x * 128 + threadIdx_x * 32 + blockIdx_y * 4 + threadIdx_y] + pad_in_1[b * 3344 + c * 836 + blockIdx_x * 152 + threadIdx_x * 38 + ki * 38 + blockIdx_y * 4 + threadIdx_y + kj] * W_1[c * 49 + ki * 7 + kj]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_dwsp_2dconv_gpu.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr6O-G7XIYcN",
        "outputId": "527cbce0-cb64-43d2-836d-b1ca5c7a89d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.4.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "plugins: anyio-3.7.1\n",
            "collected 1357 items                                                                               \u001b[0m\n",
            "\n",
            "tests/test_dwsp_2dconv_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [  4%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 11%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 18%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 24%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 31%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 38%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 45%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 52%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 58%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 65%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 72%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 79%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 85%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 92%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m [ 99%]\n",
            "\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                      [100%]\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[20] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 20\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 20x speed-up failed: TVM Time: 3.00694e-03s TorchTime: 4.63049e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0030069389999880514 * 20.0) <= 0.04630492799969943\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[30] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 30\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 30x speed-up failed: TVM Time: 2.40781e-03s TorchTime: 5.12063e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002407812000001286 * 30.0) <= 0.05120632700027272\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[40] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 40\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 40x speed-up failed: TVM Time: 2.50082e-03s TorchTime: 4.33672e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002500815000075818 * 40.0) <= 0.04336718300010034\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[50] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 50\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 50x speed-up failed: TVM Time: 2.52541e-03s TorchTime: 4.40636e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002525410000089323 * 50.0) <= 0.044063579000066966\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[60] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 60\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 60x speed-up failed: TVM Time: 2.44330e-03s TorchTime: 4.69553e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002443298999878607 * 60.0) <= 0.04695531400011532\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[70] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 70\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 70x speed-up failed: TVM Time: 2.47511e-03s TorchTime: 4.32508e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0024751119999564253 * 70.0) <= 0.04325076299983266\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[80] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 80\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 80x speed-up failed: TVM Time: 2.40211e-03s TorchTime: 4.47369e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0024021120002544194 * 80.0) <= 0.04473687900008372\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[90] _______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 90\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 90x speed-up failed: TVM Time: 2.36690e-03s TorchTime: 4.49671e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0023669009997320245 * 90.0) <= 0.044967086000269774\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m______________________________________ test1_speed_torch[100] ______________________________________\u001b[0m\n",
            "\n",
            "execution_number = 100\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 100x speed-up failed: TVM Time: 2.53857e-03s TorchTime: 4.46033e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002538570999604417 * 100.0) <= 0.044603319999623636\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[20]\u001b[0m - AssertionError: 20x speed-up failed: TVM Time: 3.00694e-03s TorchTime: 4.63049e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[30]\u001b[0m - AssertionError: 30x speed-up failed: TVM Time: 2.40781e-03s TorchTime: 5.12063e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[40]\u001b[0m - AssertionError: 40x speed-up failed: TVM Time: 2.50082e-03s TorchTime: 4.33672e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[50]\u001b[0m - AssertionError: 50x speed-up failed: TVM Time: 2.52541e-03s TorchTime: 4.40636e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[60]\u001b[0m - AssertionError: 60x speed-up failed: TVM Time: 2.44330e-03s TorchTime: 4.69553e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[70]\u001b[0m - AssertionError: 70x speed-up failed: TVM Time: 2.47511e-03s TorchTime: 4.32508e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[80]\u001b[0m - AssertionError: 80x speed-up failed: TVM Time: 2.40211e-03s TorchTime: 4.47369e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[90]\u001b[0m - AssertionError: 90x speed-up failed: TVM Time: 2.36690e-03s TorchTime: 4.49671e-02s\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[100]\u001b[0m - AssertionError: 100x speed-up failed: TVM Time: 2.53857e-03s TorchTime: 4.46033e-02s\n",
            "\u001b[31m============================ \u001b[31m\u001b[1m9 failed\u001b[0m, \u001b[32m1348 passed\u001b[0m\u001b[31m in 880.76s (0:14:40)\u001b[0m\u001b[31m ============================\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}