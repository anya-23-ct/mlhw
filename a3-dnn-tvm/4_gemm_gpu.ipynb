{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-HW-SYS/a3-anya-23-ct/blob/main/4_gemm_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# GEMM on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IcE4c-V5Psg"
      },
      "source": [
        "## 1. Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMbgGWP75Psg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e03337-c149-45fc-8c21-7ad98e9a4cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "REpyYw1o5Psi"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username\n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xmVrYXr05Psi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1427e53-4325-4187-db26-182980b37cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545\n",
            "/content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 380 bytes | 9.00 KiB/s, done.\n",
            "From https://github.com/ML-HW-SYS/a3-anya-23-ct\n",
            "   540dedd..2f1d79c  main       -> origin/main\n",
            "Updating 540dedd..2f1d79c\n",
            "Fast-forward\n",
            " src/ops.py | 7 \u001b[32m+\u001b[m\u001b[31m------\u001b[m\n",
            " 1 file changed, 1 insertion(+), 6 deletions(-)\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "# %mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "# !git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ll4LScr_5Psi"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WdiSdTlu5Psj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcad5b32-225d-48be-b207-3538d5b7a3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_conv1d_cpu.ipynb  3-conv1d_fpga.ipynb  5_conv2d_dw_gpu.ipynb\tREADME.md  tests\n",
            "2_conv1d_gpu.ipynb  4_gemm_gpu.ipynb\t leaderboard_id.txt\tsrc\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJDlW3_V5uX8"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VkqX6TEG5tz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a217792f-5d62-4b3c-99cb-6829602b95b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.12.dev/tlcpack_nightly_cu102-0.15.dev118%2Bg51bdaec6e-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.6/428.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (1.11.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from tlcpack-nightly-cu102) (4.11.0)\n",
            "Installing collected packages: tlcpack-nightly-cu102\n",
            "Successfully installed tlcpack-nightly-cu102-0.15.dev118+g51bdaec6e\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16GZ_We05Psj"
      },
      "source": [
        "## 3. Check the implementation of `make_gemm_gpu_scheduler` function in `src.ops`\n",
        "\n",
        "The function implements General Matrix Multiply (GEMM) on GPU. You should use TVM to optimize it.\n",
        "\n",
        "Let $A \\in \\mathbb{R}^{m \\times k}$, $W \\in \\mathbb{R}^{k \\times n}$, and $B \\in \\mathbb{R}^{m \\times n}$, then\n",
        "$$\n",
        "B = A \\times W\n",
        "$$\n",
        "Please see the numpy matmul function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html).\n",
        "\n",
        "The `make_gemm_gpu_scheduler` takes $m$, $k$, and $n$. The first matrix is $m \\times k$, the second matrix is $k \\times n$, and the output matrix is $m \\times n$.\n",
        "\n",
        "The function returns both the TVM scheduler and the TVM opterator for\n",
        "1. Input $a$\n",
        "2. Input $w$\n",
        "3. Output $b$\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(a, w, b)$.\n",
        "Please see the following cells for usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nIPEBHF5Psj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8d2840-fbea-4b04-a115-532363affc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: [[498.6206  497.29578 512.71533 ... 507.04666 501.69836 496.20288]\n",
            " [505.1839  502.87903 511.18536 ... 505.7803  503.62958 501.30338]\n",
            " [494.72662 507.2359  515.82007 ... 505.81396 496.44647 503.10767]\n",
            " ...\n",
            " [497.98547 507.85663 517.41156 ... 504.03702 494.86145 504.2512 ]\n",
            " [497.23294 506.19016 510.91302 ... 502.3822  493.55756 498.72968]\n",
            " [506.4279  512.9241  521.8143  ... 509.13065 507.63358 502.62515]]\n",
            "Output: [[498.61993 497.29593 512.71466 ... 507.04657 501.6985  496.20288]\n",
            " [505.18433 502.8787  511.18506 ... 505.78067 503.62964 501.30322]\n",
            " [494.72662 507.23544 515.8204  ... 505.81433 496.44653 503.10785]\n",
            " ...\n",
            " [497.9852  507.8573  517.4118  ... 504.03745 494.8614  504.2511 ]\n",
            " [497.23328 506.19003 510.9128  ... 502.38232 493.55713 498.73007]\n",
            " [506.42764 512.92377 521.8146  ... 509.13068 507.63345 502.62524]]\n",
            "GEMM TVM: 86.403068 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N)\n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"GEMM TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjnf_oPi5Psk",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0000a14e-794e-4538-a2b2-1199c54b6070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 2048), \"float32\"), B: T.Buffer((2048, 512), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 1024)\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 512)\n",
            "        C_1 = T.Buffer((524288,), data=C.data)\n",
            "        C_1[blockIdx_y * 512 + blockIdx_x] = T.float32(0)\n",
            "        for k in range(2048):\n",
            "            A_1 = T.Buffer((2097152,), data=A.data)\n",
            "            B_1 = T.Buffer((1048576,), data=B.data)\n",
            "            C_1[blockIdx_y * 512 + blockIdx_x] = C_1[blockIdx_y * 512 + blockIdx_x] + A_1[blockIdx_y * 2048 + k] * B_1[k * 512 + blockIdx_x]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQiasz7n5Psk",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503e9766-af1a-4ddf-b7cb-2459cc3376a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.4.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "plugins: anyio-3.7.1\n",
            "collected 20 items                                                                                 \u001b[0m\n",
            "\n",
            "tests/test_gemm_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                  [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================= \u001b[32m\u001b[1m20 passed\u001b[0m\u001b[32m in 25.48s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_gemm_gpu.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Optimisation"
      ],
      "metadata": {
        "id": "AIMs6c-SBgO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N)\n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"GEMM TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyjlMx27Bhj_",
        "outputId": "de3db2e9-08b4-4a38-842d-6d5582fd477e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: [[519.0353  509.1373  503.14197 ... 512.7716  501.28372 499.01343]\n",
            " [516.383   500.28494 503.69202 ... 503.76196 487.74896 495.8604 ]\n",
            " [530.76135 519.27655 514.59314 ... 523.7985  507.06186 505.90936]\n",
            " ...\n",
            " [519.6876  501.01474 504.2394  ... 502.29172 496.34    495.0815 ]\n",
            " [519.18134 504.7581  503.9147  ... 512.88446 488.27893 504.00406]\n",
            " [522.40643 501.3681  507.99384 ... 517.32556 499.3972  503.78522]]\n",
            "Output: [[519.03546 509.13724 503.1417  ... 512.7712  501.2839  499.01346]\n",
            " [516.3834  500.28485 503.69168 ... 503.76193 487.74887 495.86017]\n",
            " [530.7618  519.2765  514.5932  ... 523.798   507.06125 505.90924]\n",
            " ...\n",
            " [519.6876  501.01517 504.23926 ... 502.29147 496.34003 495.0814 ]\n",
            " [519.1815  504.75848 503.91498 ... 512.88446 488.27884 504.0041 ]\n",
            " [522.40674 501.36786 507.99387 ... 517.32544 499.39725 503.78494]]\n",
            "GEMM TVM: 6.373375 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyIKGQwmBml4",
        "outputId": "836f5f0d-76d9-4ed1-c34b-5cbfa7f4b48a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 2048), \"float32\"), B: T.Buffer((2048, 512), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 32)\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 16)\n",
            "        threadIdx_y = T.launch_thread(\"threadIdx.y\", 32)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 32)\n",
            "        C_1 = T.Buffer((524288,), data=C.data)\n",
            "        C_1[blockIdx_y * 16384 + threadIdx_y * 512 + blockIdx_x * 32 + threadIdx_x] = T.float32(0)\n",
            "        for k in range(2048):\n",
            "            A_1 = T.Buffer((2097152,), data=A.data)\n",
            "            B_1 = T.Buffer((1048576,), data=B.data)\n",
            "            C_1[blockIdx_y * 16384 + threadIdx_y * 512 + blockIdx_x * 32 + threadIdx_x] = C_1[blockIdx_y * 16384 + threadIdx_y * 512 + blockIdx_x * 32 + threadIdx_x] + A_1[blockIdx_y * 65536 + threadIdx_y * 2048 + k] * B_1[k * 512 + blockIdx_x * 32 + threadIdx_x]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_gemm_gpu.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cyH45AUBpXG",
        "outputId": "05ed91ae-785a-442f-da9a-5cb92fafd0aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.4.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-anya-23-ct\n",
            "plugins: anyio-3.7.1\n",
            "collected 20 items                                                                                 \u001b[0m\n",
            "\n",
            "tests/test_gemm_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                  [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================= \u001b[32m\u001b[1m20 passed\u001b[0m\u001b[32m in 17.94s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}